# -*- coding: utf-8 -*-
"""PrescribeAI-backend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YOGpQkh_FBVVqg3JWd08O-fuknYPaRad

### PROJECT DESCRIPTION

My final year project introduces a transformative AI-based medicine prescription system specifically designed for livestock. It aims to enhance the quality of veterinary care by providing precise medication recommendations through advanced technological integration.

### Tools and Technologies
- **Google Colab**: Facilitates an interactive development environment for machine learning models.
- **Visual Studio Code (VSCode)**: Serves as the primary code editor, enhancing productivity with powerful coding tools and extensions.
- **Next.js**: Powers the front-end framework, delivering a fast and scalable user experience.
- **Python**: The backbone programming language that drives the system's logic and data processing.
- **Machine Learning Libraries**: A suite of libraries including TensorFlow and Transformers to handle complex computations and model training.
- **Optical Character Recognition (OCR)**: Extracts text from uploaded prescription images, enabling the system to analyze and process handwritten or printed data.
- **GPT-4 by OpenAI**: Employs this state-of-the-art language model to process and understand verbal disease descriptions from livestock owners.
- **MongoDB**: Manages and stores all data interactions, ensuring robust data retrieval and security for conversation logs and medical records.

### Standout Features
- **Conversational AI**: Utilizes GPT-4 to interpret symptoms described by livestock owners, transforming verbal inputs into actionable medical advice.
- **Prescription Image Analysis**: The OCR technology not only reads but also interprets the content of uploaded prescriptions, offering detailed insights into previous medical treatments and recommendations.
- **Data Management**: MongoDB's integration ensures efficient handling of all user interactions and medical histories, making information retrieval quick and reliable. This feature is crucial for maintaining a continuous and informed treatment cycle.
- **Accessibility and Impact**: Designed to be user-friendly, the system significantly enhances access to expert-level veterinary care, especially in remote areas. This leads to improved health outcomes for livestock and supports the broader agricultural community by stabilizing and increasing productivity.

This project stands out for its innovative use of technology to make veterinary care more efficient and accessible, setting a new benchmark in the field.

Behind the scenes, the system is powered by MongoDB, ensuring efficient data management and retrieval of conversation logs and medical records. This setup not only enhances the decision-making process for immediate care but also contributes to a cumulative knowledge base that improves long-term treatment strategies.

With its integration of diverse technologies and a focus on user-friendly design, this project promises to set a new standard in veterinary medicine, making expert-level care accessible even in remote areas. This visionary approach could significantly improve health outcomes for livestock globally, benefiting the agricultural sector at large.

STORE CHAT HISTORY IN DATABASE
"""

# Installing necessary libraries for Connection with MongoDB

!pip install pymongo dnspython
!pip install "pymongo[srv]"

# Establishing a Database Connection

import pymongo
from pymongo import MongoClient

# Update this with your correctly formatted connection URI
CONNECTION_STRING = "mongodb+srv://ashfaqaqsa883:RQavPYfFiqkAmlkL@cluster0.whmef7a.mongodb.net/"

# Create a connection using MongoClient
client = MongoClient(CONNECTION_STRING)

# Define the database name
db = client["sample_mflix"]  # This should match the database name in your connection string

# Define the collection
collection = db['users']

# Test inserting a document into the collection
try:
    result = collection.insert_one({"name": "John Doe", "message": "Hello, World!", "timestamp": "2022-01-01T12:00:00Z"})
    print("Insert successful:", result.inserted_id)
except Exception as e:
    print("Error inserting document:", e)

# Test retrieving documents from the collection
try:
    documents = collection.find()
    for document in documents:
        print(document)
except Exception as e:
    print("Error retrieving documents:", e)

# Adding Features for Effective Data Processing

from pymongo import MongoClient, ASCENDING
from datetime import datetime

# Setup MongoDB connection -- connection already set so just add new collections name here
chat_history = db.chat_history

# Ensure indexes are created
chat_history.create_index([("user_id", ASCENDING), ("timestamp", ASCENDING)])

def store_message(user_id, name, message, response_data):
    """Stores a message in the database."""
    chat_history.insert_one({
        "user_id": user_id,
        "user_name": name,
        "timestamp": datetime.utcnow(),
        "User": message,
        "AI": response_data
    })

def display_history(name, history):                # #########
    print(f"Chat history for User {name}:")
    for message in history:
        sender = message['sender']
        text = message['message']
        timestamp = message['timestamp'].strftime('%Y-%m-%d %H:%M:%S')  # Format timestamp
        print(f"{timestamp} - {sender.title()}: {text}")

def on_session_start(user_id):
    # Retrieve the user's past conversation history
    history = get_chat_history(user_id)

    # Display or utilize the history as needed (e.g., to restore context or continue from where the last conversation ended)
    display_history(user_id, history)

def safe_store_message(user_id, message, sender):
    try:
        store_message(user_id, message, sender)
    except Exception as e:
        print(f"Error storing message: {e}")  # Log the error; consider how to handle failures appropriately

"""CHAT HISTORY RETRIEVAL"""

# Chat History Retrieval From Database

def get_chat_history(name):
    """Retrieves a user's chat history, sorted by timestamp."""
    messages = list(chat_history.find({"user_name": name}).sort("timestamp", ASCENDING))
    formatted_history = []

    for message in messages:
        user_message = f"User: {message['User']}"
        ai_message = f"AI : {message['AI']}"
        formatted_history.append(user_message)
        formatted_history.append(ai_message)

    # Join all formatted messages into a single string with line breaks
    return "\n".join(formatted_history)

get_chat_history("Aqsa")

"""ML MODEL FINE TUNING"""

# Installing required libraries

!pip install -U spacy==3.6.1
!pip install scispacy

!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz
!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_md-0.5.1.tar.gz
!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz

!pip install render

# Fine Tuning With NLP

import scispacy
import spacy

#Core models
import en_core_sci_sm
import en_core_sci_md

#NER specific models
import en_ner_bc5cdr_md

#Tools for extracting & displaying data
from spacy import displacy
import pandas as pd

import json
import csv

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

nltk.download('stopwords')
nltk.download('punkt')

"""The following part uses two NLP models to fine tune GPT4 model according to the context. This will make the model to extract medical information from the query."""

# Now Load the specific model: en_core_sci_md and pass text through
nlp_md = en_core_sci_sm.load()
processed_text, text = "", ""
doc = nlp_md(processed_text)   # if we replace this processed_text with the input question of user -- then

#Display resulting entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')

# Now Load the specific model: en_core_sci_md and pass text through
nlp_md = en_core_sci_md.load()
doc = nlp_md(processed_text)

#Display resulting entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')
nlp_bc = en_ner_bc5cdr_md.load()
doc = nlp_bc(text)

#Display resulting entity extraction
displacy_image = displacy.render(doc, jupyter=True,style='ent')


# Process the clinical text dropping NAN values and creating a random smaller sample for the custom entity model.
df.dropna(subset=['utterances'], inplace=True)
df_subset = df.sample(n=100, replace=False, random_state=42)
df_subset.info()
df_subset.head()

"""This part identifies and extracts the medical terms from doctor-patient conversations using SpaCy's NLP capabilities. It defines a pattern to capture entities like drugs, diseases, and symptoms from text and employs a matcher to scan conversation data for these patterns. This approach aids in systematically gathering medical data from unstructured text, useful in clinical documentation and analysis tasks."""

from spacy.matcher import Matcher

# Define a pattern for medical terms and treatments
pattern = [{'ENT_TYPE': {'IN': ['DRUG', 'DISEASE', 'SYMPTOM']}}, {'IS_ASCII': True}]
matcher = Matcher(nlp_bc.vocab)
matcher.add("MEDICAL_INFO", [pattern])

# Iterate through doctor-patient conversations
for conversation in df['utterances']:
    doc = nlp_bc(conversation)
    matches = matcher(doc)

    for match_id, start, end in matches:
        string_id = nlp_bc.vocab.strings[match_id]  # get string representation
        span = doc[start:end]  # the matched span adding drugs doses
        print(span.text, start, end, string_id)

    # Add additional medical entities
    for ent in doc.ents:
        if ent.label_ in ['DRUG', 'DISEASE', 'SYMPTOM']:
            print(ent.text, ent.start_char, ent.end_char, ent.label_)


from spacy.matcher import Matcher

# Define a pattern for medical terms and treatments
pattern = [{'ENT_TYPE': {'IN': ['DRUG', 'DISEASE', 'SYMPTOM']}}, {'IS_ASCII': True}]
matcher = Matcher(nlp_bc.vocab)
matcher.add("MEDICAL_INFO", [pattern])

# Initialize a list to store extracted information
extracted_info = set()

# Iterate through doctor-patient conversations
def extract_info(input):
    for conversation in input:
        doc = nlp_bc(conversation)
        matches = matcher(doc)

        for match_id, start, end in matches:
            string_id = nlp_bc.vocab.strings[match_id]  # get string representation
            span = doc[start:end]  # the matched span adding drugs doses
            entity_info = (span.text, start, end, string_id)
            extracted_info.add(entity_info)

        # Add additional medical entities
        for ent in doc.ents:
            if ent.label_ in ['DRUG', 'DISEASE', 'SYMPTOM']:
                entity_info = "{}, {}, {}, {}".format(ent.text, ent.start_char, ent.end_char, ent.label_)
                extracted_info.add(entity_info)

    return extracted_info

# Call the function with your DataFrame's 'description' column
result = list(extract_info(df['utterances']))

# Print or further process the extracted information
print(result)

"""GPT4 PART - QUESTION ANSWERING"""

!pip install --upgrade openai

import requests
import random

api_key = "sk-proj-bhI8ZDrOTZiaGcpT5j8gT3BlbkFJux0Z3t4SItZYfsq7i1nX"
def ask_chatgpt(query):
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    data = {
        "model": "gpt-3.5-turbo",
        "messages": [{"role": "user", "content": query}]
    }

    try:
        response = requests.post(url, json=data, headers=headers)
        response.raise_for_status()  # Raises an exception for HTTP errors
        response_data = response.json()

        # Extracting the answer text from the response
        answer = response_data.get('choices')[0].get('message').get('content')
        return answer
    except requests.RequestException as e:
        return f"An error occured {e}"

question = input("Ask anything: ")
user_id = random.randint(0, 200)
name = input("Enter title for this conversation: ")
prompt = f"Answer what I am asking related to livestock, disease. Also prescribe me names of medicines which I can give my livestock if possible.{question}"
response_data = ask_chatgpt(prompt)
store_message(user_id, name , question, response_data)
print(response_data)

"""IMAGE RECOGNITION - PRESCRIPTION ANALYSIS"""

!pip install requests

# Install pytesseract and Pillow for image processing

!sudo apt install tesseract-ocr
!pip install pytesseract pillow
!pip install openai

# Import Libraries

import pytesseract
from PIL import Image
import requests
from io import BytesIO
import openai

# Load and process the image
def load_image(image_path):
    image = Image.open(image_path)
    display(image)
    return image


# Apply OCR to the image
def extract_text(image):
    text = pytesseract.image_to_string(image)
    return text


# Putting it all together
def main(image_path):
    image = load_image(image_path)
    extracted_text = extract_text(image)
    print("Extracted Text:", extracted_text)
    prompt = f" Assume you're a health care professional and you've been trained on vast amounts of medical data. Looking at this prescription, provide more information about this prescription. {extracted_text}"
    info = ask_chatgpt(prompt)
    print("Generated Information:", info)


# Example Usage
# main('path_to_image.jpg')

# User Input in colab
from google.colab import files
uploaded = files.upload()
for filename in uploaded.keys():
    main(filename)

"""SPEECH-TO-TEXT TRANSCRIPTION"""

